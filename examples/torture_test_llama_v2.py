"""
AEE Protocol - Torture Test contra Llama 2 Local
Valida que el watermark sobrevive a reescrituras de IA
VERSION MEJORADA: strength=0.50 + embeddings multilingÃ¼es
"""

import numpy as np
import json
import requests
from datetime import datetime
from aeeprotocol.core.engine import AEEMathEngine
from sentence_transformers import SentenceTransformer

print("ğŸ”¥ AEE PROTOCOL - TORTURE TEST LLAMA (MEJORADO)\n")

# =====================================================
# CONFIGURACIÃ“N MEJORADA
# =====================================================

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama2:7b"
EMBEDDING_MODEL = "sentence-transformers/multilingual-MiniLM-L12-v2"  # MultilingÃ¼e
STRENGTH = 0.50  # MÃ¡xima robustez

print(f"ConfiguraciÃ³n:")
print(f"  - Ollama: {OLLAMA_URL}")
print(f"  - Modelo: {MODEL_NAME}")
print(f"  - Embeddings: {EMBEDDING_MODEL} (multilingÃ¼e)")
print(f"  - Strength: {STRENGTH}\n")

# =====================================================
# INICIALIZAR
# =====================================================

print("ğŸ“¥ Cargando modelo de embeddings multilingÃ¼e...")
embedding_model = SentenceTransformer(EMBEDDING_MODEL)
print(f"âœ“ Embeddings cargado (dimensiÃ³n: 384)\n")

engine = AEEMathEngine(strength=STRENGTH)
print(f"âœ“ Engine AEE inicializado (strength: {engine.strength}, threshold: {engine.threshold:.4f})\n")

# =====================================================
# TEXTOS DE PRUEBA
# =====================================================

test_texts = [
    "El watermarking vectorial es una tÃ©cnica criptogrÃ¡fica para proteger embeddings de inteligencia artificial de uso no autorizado.",
    "Los embeddings son representaciones numÃ©ricas de texto en espacios vectoriales de alta dimensiÃ³n que capturan significado semÃ¡ntico.",
    "La trazabilidad de datos es crÃ­tica en auditorÃ­as de modelos de lenguaje para verificar conformidad con regulaciones."
]

results = {
    'timestamp': datetime.now().isoformat(),
    'model': MODEL_NAME,
    'embedding_model': EMBEDDING_MODEL,
    'strength': engine.strength,
    'threshold': engine.threshold,
    'tests': [],
    'summary': {}
}

# =====================================================
# TORTURE TEST
# =====================================================

print("="*70)
print("ğŸ”¥ INICIANDO TORTURE TEST (VERSIÃ“N MEJORADA)")
print("="*70)
print(f"Textos: {len(test_texts)}")
print(f"Reescrituras por texto: 3")
print(f"Total de tests: {len(test_texts) * 3}\n")

watermarks_survived = 0
total_tests = 0

for text_idx, original_text in enumerate(test_texts, 1):
    print(f"\n{'â”€'*70}")
    print(f"TEXTO {text_idx}: {original_text[:60]}...")
    print(f"{'â”€'*70}")
    
    # Step 1: Embedding original
    print(f"\n[1/4] Generando embedding original...")
    original_embedding = embedding_model.encode(original_text)
    original_embedding = original_embedding / np.linalg.norm(original_embedding)
    print(f"      âœ“ Embedding: {original_embedding.shape}")
    
    # Step 2: Watermark
    print(f"[2/4] Inyectando watermark...")
    marked_embedding, metadata = engine.inject(original_embedding, user_id=35664619)
    initial_detection = engine.detect(marked_embedding, user_id=35664619)
    print(f"      âœ“ Watermark inyectado")
    print(f"      âœ“ Similitud inicial: {initial_detection:.4f} (threshold: {engine.threshold:.4f})")
    
    # Step 3: Reescrituras
    rewrite_prompts = [
        f"Reescribe esta frase de forma mÃ¡s clara y concisa: {original_text}",
        f"Parafrasea manteniendo exactamente el significado: {original_text}",
        f"Expresa la misma idea con otras palabras pero sin perder contenido: {original_text}"
    ]
    
    for iter_num, prompt in enumerate(rewrite_prompts, 1):
        print(f"\n   [ITERACIÃ“N {iter_num}/3]")
        print(f"   [3/4] Reescribiendo con Llama...")
        
        try:
            # Llamar a Ollama
            response = requests.post(
                OLLAMA_URL,
                json={
                    "model": MODEL_NAME,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 120
                    }
                },
                timeout=60
            )
            
            if response.status_code != 200:
                print(f"       âŒ Error Ollama: {response.status_code}")
                continue
            
            rewritten_text = response.json()['response'].strip()
            print(f"       Original: {original_text[:50]}...")
            print(f"       Reescrito: {rewritten_text[:50]}...")
            
            # Step 4: Embedding reescrito
            print(f"   [4/4] Obteniendo embedding reescrito...")
            rewritten_embedding = embedding_model.encode(rewritten_text)
            rewritten_embedding = rewritten_embedding / np.linalg.norm(rewritten_embedding)
            
            # Detectar watermark
            detection_score = engine.detect(rewritten_embedding, user_id=35664619)
            detected = detection_score > engine.threshold
            
            total_tests += 1
            if detected:
                watermarks_survived += 1
                status = "âœ… SOBREVIVIÃ“"
            else:
                status = "âŒ PERDIDO"
            
            print(f"       {status}")
            print(f"       Similitud: {detection_score:.4f}")
            
            results['tests'].append({
                'text_idx': text_idx,
                'iteration': iter_num,
                'original': original_text,
                'rewritten': rewritten_text,
                'detected': detected,
                'similarity': float(detection_score),
                'threshold': float(engine.threshold)
            })
        
        except requests.exceptions.ConnectionError:
            print(f"       âŒ Error: No puedo conectar a Ollama")
            print(f"          Â¿Ollama estÃ¡ corriendo en {OLLAMA_URL}?")
            break
        except Exception as e:
            print(f"       âŒ Error: {e}")

# =====================================================
# RESUMEN
# =====================================================

print(f"\n\n{'='*70}")
print("ğŸ“Š RESUMEN DE TORTURE TEST")
print(f"{'='*70}")

if total_tests > 0:
    survival_rate = watermarks_survived / total_tests
    results['summary'] = {
        'total_tests': total_tests,
        'watermarks_survived': watermarks_survived,
        'watermarks_lost': total_tests - watermarks_survived,
        'survival_rate': float(survival_rate)
    }
    
    print(f"Total de tests: {total_tests}")
    print(f"Watermarks sobrevivieron: {watermarks_survived}")
    print(f"Watermarks perdidos: {total_tests - watermarks_survived}")
    print(f"Tasa de supervivencia: {survival_rate:.1%}")
    
    if survival_rate > 0.8:
        print(f"\nâœ… RESULTADO: PROTOCOLO ROBUSTO")
    elif survival_rate > 0.5:
        print(f"\nâš ï¸  RESULTADO: PROTOCOLO MODERADO - Buenas bases pero mejora posible")
    else:
        print(f"\nâŒ RESULTADO: PROTOCOLO DÃ‰BIL - Necesita mejoras significativas")
else:
    print("âŒ No se ejecutaron tests (posiblemente error de conexiÃ³n)")

# Guardar resultados
output_file = f"torture_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
with open(output_file, 'w') as f:
    json.dump(results, f, indent=2)

print(f"\nğŸ’¾ Resultados guardados en: {output_file}")
print(f"\nâœ… Torture test completado")